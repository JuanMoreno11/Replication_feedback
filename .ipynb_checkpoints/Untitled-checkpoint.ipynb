{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(siedco, convergencia = 0.05, dist_max = 0.3, dist_t_max=90):\n",
    "    \"\"\"Funcion para entrenar el modelo de prediccion de crimen de Bogota como un proceso puntual autoexcitado\n",
    "     Metodología basada en Mohler et al. (2012) Self-Exciting Point Process Modeling of Crime \n",
    "    \n",
    "     localidad: Localidad en que se entrena el modelo. Tiene en cuenta crímenes ocurridos a una dist_max de la frontera de la localidad.\n",
    "     fecha_inicial: Fecha de inicio de los datos de entrenamiento\n",
    "     fecha_final: Fecha final de los datos de entrenamiento\n",
    "     convergencia: Parametro de convergencia del modelo\n",
    "     dist_max: Distancia espacial maxima para ser considerado un crimen replica de otro\n",
    "     dist_t_max: Distancia temporal maxima para ser considerado un crimen replica de otro\n",
    "\n",
    "     Retorna:\n",
    "     Kernels que capturan patrones espacio-temporales y de replica de crimenes, datos de entrenamiento utilizados, codigo de la localidad, tiempo de entrenamiento, y nivel de convergencia alcanzado \n",
    "\n",
    "    \"\"\"\n",
    "    k_g = 80\n",
    "    k_mu = 15\n",
    "    bw_nu = 0.01   \n",
    "    \n",
    "    #siedco = datos_procesados(localidad, fecha_inicial, fecha_final, dist_max)\n",
    "\n",
    "    restas = matriz_distancias(siedco[['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']])\n",
    "\n",
    "    inicio = time.time()\n",
    "\n",
    "    N = len(siedco)\n",
    "    lejanos = restas.index[(restas['distancia']>dist_max) | (restas['turno_lineal']>dist_t_max)]\n",
    "    P = iniciarP(N, restas, lejanos)\n",
    "    restas = restas[['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]\n",
    "    conv = [2]\n",
    "    rep = []\n",
    "    trans = []\n",
    "\n",
    "    print('Inicio entrenamiento')\n",
    "    \n",
    "    while (conv[-1]>convergencia) & (len(conv)<=50):\n",
    "        # Muestreo eventos de trasfondo\n",
    "        # Retorna una matriz con un 1 en cada columna indicando, en la fila, el evento que lo causo\n",
    "        # si i=j el evento es de trasfondo. Si i!=j, el evento i causo j.\n",
    "        muestreo = np.vstack(tuple(np.random.multinomial(1, P[:,k], size=1) for k in range(N)))\n",
    "        trasfondo = siedco.iloc[(np.where(np.diag(muestreo)==1))[0]]\n",
    "\n",
    "        #Separar datos de trasfondo y replicas\n",
    "        #Trasfondo:\n",
    "        np.fill_diagonal(muestreo, 0)\n",
    "        replicas = np.where(muestreo==1)\n",
    "        densidadG = pd.DataFrame([0 for i in restas.index], index= restas.index)\n",
    "        replicas = [(replicas[0][i],replicas[1][i]) for i in range(len(replicas[0]))]\n",
    "        replicas=restas.loc[replicas]\n",
    "        rep.append(len(replicas))\n",
    "        print('Replicas: ' + str(len(replicas)/len(siedco)))\n",
    "        \n",
    "        #if len(replicas[0])>3:\n",
    "            #entrena el kernel g con los datos de réplicas\n",
    "        #    replicas = [(replicas[0][i],replicas[1][i]) for i in range(len(replicas[0]))]\n",
    "        #    replicas=restas.loc[replicas]\n",
    "        #    kdeG = KDEMultivariate(replicas, bw='cv_ml', var_type='ccu')\n",
    "        #    rep.append(len(replicas))\n",
    "\n",
    "        #else:\n",
    "        #    replicas = pd.DataFrame(np.zeros((4,3)),index=restas.index[0:4])\n",
    "        #    kdeG = KDEMultivariate(replicas, bw=[1,1,1], var_type='cco')\n",
    "        #    rep.append(0)\n",
    "\n",
    "        #densidadG[~densidadG.index.isin(lejanos)] = pd.DataFrame(kdeG.pdf(restas[~densidadG.index.isin(lejanos)]), index = densidadG[~densidadG.index.isin(lejanos)].index)\n",
    "\n",
    "        #if len(trasfondo)>0:\n",
    "            #entrena el kernel mu (espacial) con los datos de trasfondo\n",
    "        #    kdeMu = KDEMultivariate(trasfondo[['LONGITUD_X','LATITUD_Y']], bw='cv_ml', var_type='cc')\n",
    "\n",
    "            #entrena el kernel nu (temporal ciclico) con los datos de trasfondo\n",
    "        #    kdeNu = KDEMultivariate(trasfondo[['turno_circular']], bw='cv_ml', var_type='u')\n",
    "\n",
    "        #    trans.append(len(trasfondo))\n",
    "\n",
    "        #else:\n",
    "        #    trasfondo = pd.DataFrame(np.zeros((3,4)))\n",
    "        #    trasfondo.columns = siedco.columns\n",
    "        #    kdeMu = KDEMultivariate(trasfondo[['LONGITUD_X','LATITUD_Y']], bw=[1,1], var_type='cc')\n",
    "        #    kdeNu = KDEMultivariate(trasfondo[['turno_circular']], bw=[1], var_type='o')\n",
    "        #    trans.append(0)\n",
    "\n",
    "        #densidadMu = kdeMu.pdf(siedco[['LONGITUD_X','LATITUD_Y']])\n",
    "        #densidadNu = kdeNu.pdf(siedco[['turno_circular']])\n",
    "        \n",
    "        try:\n",
    "            densidadG = pd.DataFrame([0 for i in restas.index], index= restas.index)\n",
    "            densidadG[~restas.index.isin(lejanos)] = restas[~restas.index.isin(lejanos)].apply(kernel_g, axis = 1, args = (replicas, N, k_g))\n",
    "            \n",
    "            densidadMu = siedco.apply(kernel_mu, axis = 1, args = (siedco, N, k_mu))\n",
    "    \n",
    "            densidadNu = pd.Series(np.ones(len(siedco)))\n",
    "        \n",
    "            lam = np.concatenate([densidadNu[x]*densidadMu[x] + sum(densidadG.loc[x].values) for x in range(1,N)])\n",
    "\n",
    "            lam = np.insert(lam, 0, densidadNu[0]*densidadMu[0])\n",
    "\n",
    "            Pvieja = P\n",
    "\n",
    "            #Actualizacion P\n",
    "\n",
    "            P = np.hstack(list(map(lambda x: np.concatenate((np.array(densidadG.loc[[(x,i) for i in range(x)]]/lam[x]),\n",
    "                                                             np.array([0 for i in range(N-x)]).reshape((N-x,1)))), range(N))))\n",
    "            noCeros = [i for i in range(len(lam)) if lam[i]!=0]\n",
    "            P[range(N), range(N)] = 0\n",
    "            P[[i for i in range(N) if i in noCeros],[i for i in range(N) if i in noCeros]] = [densidadMu[j]*densidadNu[j]/lam[j] for j in range(N) if j in noCeros]\n",
    "\n",
    "            conv.append(np.linalg.norm(Pvieja - P)/np.linalg.norm(Pvieja))\n",
    "\n",
    "            #print(\"Termino iteracion localidad \" + localidad + ' ' + str(time.time()) + '. Convergencia: ' + str(conv[-1])  )\n",
    "            print(\"Termino iteracion \" + str(time.time()) + '. Convergencia: ' + str(conv[-1])  )\n",
    "        \n",
    "        except:\n",
    "            print('Reinicia entrenamiento')\n",
    "            restas = matriz_distancias(siedco[['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']])\n",
    "            P = iniciarP(N, restas, lejanos)\n",
    "            restas = restas[['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]\n",
    "            if k_g-10 >= 50:\n",
    "                k_g = k_g-10\n",
    "            else:\n",
    "                conv.append(0)            \n",
    "        \n",
    "    #graficar_resultados(conv[1::], directorio+'/plots/'+'_'.join(['conv', localidad, descriptor]), convergencia, kind = 'Convergencia')\n",
    "    #graficar_resultados(rep, directorio+'/plots/'+'_'.join(['rep', localidad, descriptor]), kind = '# Crímenes Réplica')\n",
    "    #graficar_resultados(trans, directorio+'/plots/'+'_'.join(['trans', localidad, descriptor]), kind = '# Crímenes Transfondo')\n",
    "\n",
    "    tiempo = ((time.time() - inicio)/60)\n",
    "\n",
    "    #return {'g': kdeG, 'mu': kdeMu, 'nu': kdeNu, 'datos': siedco, 'replicas': replicas, 'cod_localidad':localidad, 'tiempo_entrenamiento':tiempo, 'convergencia':conv[-1]}\n",
    "    #return {'datos': siedco, 'replicas': replicas, 'cod_localidad':localidad, 'tiempo_entrenamiento':tiempo, 'convergencia':conv[-1]}\n",
    "    return {'datos': siedco, 'replicas': replicas, 'tiempo_entrenamiento':tiempo, 'convergencia':conv[-1]}\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "    \"\"\"Funcion para obtener la distancia Haversine de dos puntos. Tiene en cuenta la curvatura de la tierra.\n",
    "    slightly modified version: of http://stackoverflow.com/a/29546836/2901002\n",
    "\n",
    "    lat1: Latitud del primer punto\n",
    "    lon1: Longitud del primer punto\n",
    "    lat2: Latitud del segundo punto\n",
    "    lon2: Longitud del segundo punto\n",
    "    to_radians: Parametro que indica si las coordenadas deben ser convertidas a radianes\n",
    "    earth_radius: Radio de la tierra\n",
    "        \n",
    "    Retorna:\n",
    "    Distancia Haversine entre dos puntos especificados\n",
    "    \"\"\"\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return pd.Series(earth_radius * 2 * np.arcsin(np.sqrt(a)))\n",
    "\n",
    "\n",
    "def matriz_distancias(datos):\n",
    "    \"\"\"Construccion de matriz de distancias espacio-temporales de los crimenes\n",
    "    \n",
    "     datos: Datos historicos de crimenes\n",
    "\n",
    "     Retorna:\n",
    "     Matriz de distancias espaciales y temporales de los crimenes ocurridos en la base de datos\n",
    "\n",
    "    \"\"\"\n",
    "    N = len(datos)\n",
    "    new = list(map(lambda x: datos.iloc[(N-x):].reset_index(drop = True)-datos.iloc[:x], [i for i in reversed(range(1,N))]))\n",
    "    new = pd.concat(new)\n",
    "    new = new.assign(indice0 = pd.concat(list(map(lambda x: pd.Series([i for i in range(N-1-x)]), [i for i in range(N-1)]))))\n",
    "    new = new.assign(indice1 =pd.concat(list(map(lambda x: pd.Series([i for i in range(x,N)]), [i for i in range(1,N)])) ))\n",
    "    new = new.assign(distancia = pd.concat(list(map(lambda x: haversine(datos['LATITUD_Y'].iloc[(N-x):].reset_index(drop = True), datos['LONGITUD_X'].iloc[(N-x):].reset_index(drop = True), datos['LATITUD_Y'].iloc[:x].reset_index(drop = True), datos['LONGITUD_X'].iloc[:x].reset_index(drop = True)) , [i for i in reversed(range(N))]))))\n",
    "    new = new.set_index(['indice1', 'indice0'], drop=True)\n",
    "    return new\n",
    "\n",
    "def iniciarP(N, restas, lejanos, uniforme = False):\n",
    "    \"\"\"Inicializacion de la matriz P\n",
    "    \n",
    "     N: Numero de eventos en la base de datos\n",
    "     restas: Matriz de distancias espacio-temporales de los crimenes\n",
    "     lejanos: Indices de los eventos que no pueden ser considerados replica por superar maxima distancia espacial o temporal permitidas\n",
    "     uniforma: Parametro que indica como se inicializa la matriz, si uniforme = True se inicializa con una distribucion uniforme, de lo contrario con normal bivariada en espacio y exponencial en tiempo\n",
    "\n",
    "     Retorna:\n",
    "     Matriz P inicial de probabilidades de ser crimen de transfondo o replica\n",
    "\n",
    "    \"\"\"\n",
    "    if uniforme:\n",
    "        P = np.transpose(np.vstack((np.concatenate(([1], [0 for j in range(N-1)])),tuple(np.concatenate((np.array([0.5/(i-1) for j in range(i-1)]),[0.5], [0 for j in range(N-i)])) for i in range(2,N+1)))))\n",
    "    else:\n",
    "        temp = pd.DataFrame(np.exp(-restas['turno_lineal']/14)*np.exp(-(restas['distancia']**2)/(2*0.3**2)))\n",
    "        temp.reset_index(inplace=True)\n",
    "        temp = temp.sort_values(['indice1', 'indice0'])\n",
    "        P = np.transpose(np.vstack((np.concatenate(([1], [0 for j in range(N-1)])), tuple(np.concatenate((np.array(temp[temp['indice1']==i][0]), [1], [0 for j in range(N-i-1)])) for i in range(1, N)))))\n",
    "    P[[b for (a,b) in lejanos],[a for (a,b) in lejanos]] = 0\n",
    "    P = P/P.sum(axis=0)\n",
    "    return P\n",
    "\n",
    "def kernel_nu(punto, datos, N, k=100):\n",
    "\n",
    "    temp = datos/datos.std()\n",
    "    neighbors = NearestNeighbors(n_neighbors=k).fit(temp)\n",
    "    try:\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    except:\n",
    "        neighbors = NearestNeighbors(n_neighbors=len(temp)).fit(temp)\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    \n",
    "    vecinos[np.where(vecinos==0)[0]]=min(vecinos[np.where(vecinos>0)[0]])\n",
    "    vecinos = pd.DataFrame(vecinos)\n",
    "    vecinos.columns = datos.columns\n",
    "    \n",
    "    nu = (punto - datos)**2\n",
    "    nu.reset_index(drop=True, inplace=True)\n",
    "    nu = nu/(2*datos.std()**2*vecinos**2)\n",
    "    nu = np.exp(-nu)\n",
    "    nu = nu/(datos.std()*(2*np.pi)**(1/2)*vecinos)\n",
    "    return nu['turno_circular'].sum()/N\n",
    "\n",
    "\n",
    "def kernel_mu(punto, datos, N, k=15):\n",
    "\n",
    "    datos = datos[datos['turno_circular'] == punto['turno_circular']]\n",
    "    datos = datos[['LONGITUD_X', 'LATITUD_Y']]\n",
    "    punto = punto[['LONGITUD_X', 'LATITUD_Y']]\n",
    "    temp = datos/datos.std()\n",
    "    neighbors = NearestNeighbors(n_neighbors=k).fit(temp)\n",
    "    try:\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    except:\n",
    "        neighbors = NearestNeighbors(n_neighbors=len(temp)).fit(temp)\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    \n",
    "    vecinos[np.where(vecinos==0)[0]] = min(vecinos[np.where(vecinos>0)[0]])\n",
    "    vecinos = pd.DataFrame({'LONGITUD_X': vecinos, 'LATITUD_Y': vecinos})\n",
    "    \n",
    "    mu = (punto - datos)**2\n",
    "    mu.reset_index(drop=True, inplace=True)\n",
    "    mu = mu/(2*datos.std()**2*vecinos**2)\n",
    "    mu = mu.sum(axis=1)\n",
    "    mu = np.exp(-mu)\n",
    "    mu = mu/(np.prod(datos.std())*(2*np.pi)*vecinos['LONGITUD_X']**2)\n",
    "    return mu.mean()\n",
    "\n",
    "\n",
    "def kernel_g(punto, datos, N, k=15):\n",
    "\n",
    "    temp = datos/datos.std()\n",
    "    neighbors = NearestNeighbors(n_neighbors=k).fit(temp)\n",
    "    try:\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    except:\n",
    "        neighbors = NearestNeighbors(n_neighbors=len(temp)).fit(temp)\n",
    "        vecinos = neighbors.kneighbors(temp)[0][:,-1]\n",
    "    \n",
    "    vecinos[np.where(vecinos==0)[0]] = min(vecinos[np.where(vecinos>0)[0]])\n",
    "    vecinos = pd.DataFrame({'LONGITUD_X': vecinos, 'LATITUD_Y': vecinos, 'turno_lineal':vecinos})\n",
    "    \n",
    "    g = (punto - datos)**2\n",
    "    g.reset_index(drop=True, inplace=True)\n",
    "    g = g/(2*datos.std()**2*vecinos**2)\n",
    "    g = g.sum(axis=1)\n",
    "    g = np.exp(-g)\n",
    "    g = g/(np.prod(datos.std())*(2*np.pi)**(3/2)*vecinos['LONGITUD_X']**3)\n",
    "\n",
    "    return g.sum()/N\n",
    "\n",
    "\n",
    "def temperatura_ventana(punto, datos_entrenamiento, replicas, dist_max=0.3):\n",
    "    \"\"\"Retorna la intensidad esperada de crimen para un punto geografico y turno especificado, en la ventana de evaluacion \n",
    "\n",
    "     Parametros:\n",
    "     lon: Longitud del punto a evaluar\n",
    "     lat: Latitud del punto a evaluar\n",
    "     ventana_linal: Ventana de evaluacion del punto\n",
    "     turno_circular: Turno para la evaluacion\n",
    "     localidad: Localidad a la que pertenece el punto y para la cual se debe cargar la densidad respectiva\n",
    "     descriptor: Version del modelo deseada\n",
    "     dist_max: Distancia maxima entre crimenes considerados replica\n",
    "\n",
    "     Retorna:\n",
    "     valor promedio en la ventana de evaluacion de la intensidad en el punto geográfico y turno especificados.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #grilla = pd.DataFrame({'LONGITUD_X': lon, 'LATITUD_Y':lat,\n",
    "        #                       'turno_circular':[turno_circular]})\n",
    "        grilla = pd.DataFrame(punto).T\n",
    "        grilla.reset_index(drop=True, inplace=True)\n",
    "        #densidades = cargar_densidades(localidad, descriptor)\n",
    "\n",
    "        #nu = densidades['nu']\n",
    "        #mu = densidades['mu']\n",
    "        #g = densidades['g']\n",
    "        #datos_entrenamiento = densidades['datos']\n",
    "\n",
    "        datos_entrenamiento['lon_rad'] = np.radians(datos_entrenamiento['LONGITUD_X'])\n",
    "        datos_entrenamiento['lat_rad'] = np.radians(datos_entrenamiento['LATITUD_Y'])\n",
    "        grilla['lon_rad'] = np.radians(grilla['LONGITUD_X'])\n",
    "        grilla['lat_rad'] = np.radians(grilla['LATITUD_Y'])\n",
    "\n",
    "        distancia = 6371*DistanceMetric.get_metric('haversine').pairwise(grilla[['lon_rad', 'lat_rad']], datos_entrenamiento[['lon_rad', 'lat_rad']])\n",
    "        distancia = distancia.min(axis=0)\n",
    "\n",
    "        #datos_entrenamiento = datos_entrenamiento[distancia<dist_max].reset_index(drop=True)\n",
    "\n",
    "        #densidadMu = mu.pdf(grilla[['LONGITUD_X', 'LATITUD_Y']])\n",
    "        #densidadNu = nu.pdf(grilla[['turno_circular']])\n",
    "\n",
    "        #intensidades = list()\n",
    "\n",
    "\n",
    "        #for time in ventana_lineal:\n",
    "        #    grilla['turno_lineal'] = time\n",
    "\n",
    "        #    g_temp = grilla.loc[0,['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]\n",
    "        #    datos_entrenamiento_temp = datos_entrenamiento.loc[:,['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]\n",
    "        #    resta = g_temp - datos_entrenamiento_temp\n",
    "\n",
    "        #    densidadG = np.sum(g.pdf(resta))\n",
    "\n",
    "        #    intensidades.append(densidadMu*densidadNu + densidadG)\n",
    "\n",
    "\n",
    "        #return np.mean(intensidades)\n",
    "        \n",
    "        k_g = 300\n",
    "        k_mu = 5\n",
    "        \n",
    "        N = len(datos_entrenamiento)\n",
    "        densidadMu = kernel_mu(grilla.loc[0], datos_entrenamiento, N, k_mu)        \n",
    "        if min(distancia)>=dist_max:\n",
    "            return(densidadMu/3)\n",
    "        else:\n",
    "            datos_entrenamiento = datos_entrenamiento[distancia<dist_max].reset_index(drop=True)\n",
    "            #replicas = densidades['replicas']\n",
    "            \n",
    "            g_temp = grilla.loc[0, ['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]-datos_entrenamiento[['LONGITUD_X', 'LATITUD_Y', 'turno_lineal']]\n",
    "            g_temp = g_temp.apply(kernel_g, axis = 1, args = (replicas, N, k_g))\n",
    "            densidadG = np.sum(g_temp)        \n",
    "            intensidad = densidadMu + densidadG\n",
    "        return(intensidad)\n",
    "        \n",
    "    except:\n",
    "        #print('Error: ' + str(lat) + ', ' + str(lon) + ', ' + str(turno_circular))\n",
    "        print('Error')\n",
    "        return(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(urn, value, j, col):\n",
    "    result=urn.iloc[j,col]+10*value\n",
    "    return(result)\n",
    "def trial_bernoulli(urn, col):\n",
    "    proportions=np.array(urn.iloc[:, col]/urn.iloc[:, col].sum())\n",
    "    rand=[]\n",
    "    for i in range(len(proportions)):\n",
    "        rand.append(random.uniform(0,1))\n",
    "    boolean=[]\n",
    "    for i in range(len(proportions)):\n",
    "        boolean.append(rand[i]<proportions[i])\n",
    "    return(boolean)\n",
    "def one_t(urn, col):\n",
    "    for i in range(urn.shape[0]):\n",
    "        boolean=trial_bernoulli(urn, col)\n",
    "        if sum(boolean)==urn.shape[0]:\n",
    "            urn.iloc[i,(col+1)]=add(urn, urn.iloc[i,(col+1)], i, col)\n",
    "        else:\n",
    "            urn.iloc[i,(col+1)]=urn.iloc[i,(col)]\n",
    "    return(urn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Mateo/downloads/sesgos_data_santafe.csv')\n",
    "data=pd.read_csv('C:/Users/jsmor/Dropbox (Quantil)/Crimen/AddressBias/sesgos_data.csv')\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data.Fecha=pd.to_datetime(data.Fecha)\n",
    "data.columns=['Neighborhood', 'Date', 'tot_crimes', 'reports', 'homicides']\n",
    "data['discovered']=data['tot_crimes']-data['reports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
